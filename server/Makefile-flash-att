flash_attention_commit := v2.0.4

flash-attention:
    # Clone flash attention
	pip install packaging
	git clone git@github.com:Dao-AILab/flash-attention.git
	cd flash-attention && git fetch && git checkout $(flash_attention_commit)

install-flash-attention: flash-attention
	pip uninstall flash-attention -y || true
	cd flash-attention && pip install .
	cd flash-attention/csrc/layer_norm && pip install . 
	cd flash-attention/csrc/rotary && pip install . 


test-flash-attention: flash-attention
	pip install pytest
	cd flash-attention && pytest -q -s tests/test_flash_attn.py